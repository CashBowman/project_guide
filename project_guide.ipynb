{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lv_Fy-bReuqu",
        "7Y3J5zKeewXl",
        "ZaFfofvOf0i5",
        "wK-La-LHg1eq",
        "C1e_GL4Vg5Q8",
        "jivM2I2-hHF7",
        "IOk-gXqXhQL3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bash"
      ],
      "metadata": {
        "id": "2TUnRtDberHJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PspmiuU9envW"
      },
      "outputs": [],
      "source": [
        "mkdir ...\n",
        "# Create a virtual environment\n",
        "python -m venv .venv # creates a venv folder\n",
        ".venv/Scripts/Activate.ps1\n",
        "pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "QHBCHAUTesmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USUALS:\n",
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import pyplot as px\n",
        "\n",
        "# SCIKIT LEARN:\n",
        "import sklearn as skl\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TENSORFLOW:\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Gradient Boosting:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
      ],
      "metadata": {
        "id": "NxMQoEiUfNaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas"
      ],
      "metadata": {
        "id": "lv_Fy-bReuqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🐼 Pandas Cheatsheet\n",
        "\n",
        "## 1. Basics\n",
        "\n",
        "### Import Pandas\n",
        "import pandas as pd\n",
        "\n",
        "### Load CSV\n",
        "df = pd.read_csv('filename.csv')\n",
        "\n",
        "### Show Top Rows\n",
        "df.head()\n",
        "\n",
        "### Show Bottom Rows\n",
        "df.tail()\n",
        "\n",
        "### Get Shape (rows, columns)\n",
        "df.shape\n",
        "\n",
        "### Show Column Names\n",
        "df.columns\n",
        "\n",
        "### Show Data Types\n",
        "df.dtypes\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Column & Row Selection\n",
        "\n",
        "### Select Column\n",
        "df['col']\n",
        "df.col  # if no spaces in column name\n",
        "\n",
        "### Select Multiple Columns\n",
        "df[['col1', 'col2']]\n",
        "\n",
        "### Select Row by Integer Position\n",
        "df.iloc[3]\n",
        "\n",
        "### Select Row by Label\n",
        "df.loc[3]\n",
        "\n",
        "### Boolean Filter\n",
        "df[df['col'] > 100]\n",
        "\n",
        "### Filter with Multiple Conditions\n",
        "df[(df['col1'] > 50) & (df['col2'] == 'A')]\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Sorting & Indexing\n",
        "\n",
        "### Sort by Column\n",
        "df.sort_values('col')\n",
        "\n",
        "### Sort by Multiple Columns\n",
        "df.sort_values(['col1', 'col2'], ascending=[True, False])\n",
        "\n",
        "### Set Index\n",
        "df.set_index('col', inplace=True)\n",
        "\n",
        "### Reset Index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Data Cleaning\n",
        "\n",
        "### Rename Columns\n",
        "df.rename(columns={'old': 'new'}, inplace=True)\n",
        "\n",
        "### Drop Missing Rows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "### Fill Missing Values\n",
        "df['col'].fillna(0, inplace=True)\n",
        "\n",
        "### Replace Values\n",
        "df['col'].replace({'old_val': 'new_val'}, inplace=True)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Creating & Modifying Columns\n",
        "\n",
        "### Create New Column\n",
        "df['new_col'] = df['a'] + df['b']\n",
        "\n",
        "### Apply Function to Column\n",
        "df['col'] = df['col'].apply(lambda x: x.upper())\n",
        "\n",
        "### Bin Column\n",
        "df['bin'] = pd.cut(df['col'], bins=3)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Grouping & Aggregation\n",
        "\n",
        "### Groupby Mean\n",
        "df.groupby('group_col')['val_col'].mean()\n",
        "\n",
        "### Groupby Multiple Aggs\n",
        "df.groupby('group_col').agg({'val1': 'mean', 'val2': 'sum'})\n",
        "\n",
        "### Pivot Table\n",
        "df.pivot_table(index='group', columns='type', values='value', aggfunc='sum')\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Joining & Merging\n",
        "\n",
        "### Merge Two DataFrames\n",
        "pd.merge(df1, df2, on='key', how='inner')\n",
        "\n",
        "### Concatenate (Stack Vertically)\n",
        "pd.concat([df1, df2], axis=0)\n",
        "\n",
        "### Concatenate (Join Side-by-Side)\n",
        "pd.concat([df1, df2], axis=1)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Exporting Data\n",
        "\n",
        "### Save to CSV\n",
        "df.to_csv('filename.csv', index=False)\n",
        "\n",
        "### Save to Excel\n",
        "df.to_excel('filename.xlsx', index=False)\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Common Summary Functions\n",
        "\n",
        "### Describe (Summary Stats)\n",
        "df.describe()\n",
        "\n",
        "### Unique Values\n",
        "df['col'].unique()\n",
        "\n",
        "### Value Counts\n",
        "df['col'].value_counts()\n",
        "\n",
        "### Check for Nulls\n",
        "df.isnull().sum()\n",
        "\n",
        "### Correlation Matrix\n",
        "df.corr()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "bePV7jhcev7X",
        "outputId": "a257b8e9-3b9d-40bc-f769-fec3c1e18a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1-2802057510.py, line 26)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-2802057510.py\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "7Y3J5zKeewXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔥 PyTorch Cheatsheet\n",
        "\n",
        "## 1. Setup & Basics\n",
        "\n",
        "### Import PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "### Check Version\n",
        "torch.__version__\n",
        "\n",
        "### Manual Seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Tensor Operations\n",
        "\n",
        "### Create Tensor from Data\n",
        "x = torch.tensor([[1., 2.], [3., 4.]])\n",
        "\n",
        "### Random Tensor (Normal)\n",
        "x = torch.randn(4, 3)\n",
        "\n",
        "### Zeros / Ones\n",
        "z = torch.zeros(2, 5)\n",
        "o = torch.ones(2, 5)\n",
        "\n",
        "### Shape & Reshape\n",
        "x.shape\n",
        "x = x.view(-1, 6)\n",
        "\n",
        "### Concatenate\n",
        "y = torch.cat((a, b), dim=0)\n",
        "\n",
        "### Element-wise Math\n",
        "out = x * y + 10\n",
        "\n",
        "---\n",
        "\n",
        "## 3. CUDA / MPS Devices\n",
        "\n",
        "### Select Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "### Move Tensor to GPU\n",
        "x = x.to(device)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Autograd & Gradients\n",
        "\n",
        "### Require Gradients\n",
        "x = torch.randn(3, 3, requires_grad=True)\n",
        "\n",
        "### Compute y and Backprop\n",
        "y = (x ** 2).sum()\n",
        "y.backward()\n",
        "x.grad\n",
        "\n",
        "### Disable Gradient Context\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Neural Networks (nn Module)\n",
        "\n",
        "### Define Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "### Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Data Loading\n",
        "\n",
        "### Custom Dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X, self.y = X, y\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(MyDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Training Loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch {epoch}: {loss.item():.4f}')\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Evaluation\n",
        "\n",
        "model.eval()\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        pred = model(x.to(device)).argmax(1)\n",
        "        correct += (pred == y.to(device)).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "print(f'Accuracy: {100*correct/total:.2f}%')\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Save / Load Model\n",
        "\n",
        "### Save Weights\n",
        "torch.save(model.state_dict(), 'model.pt')\n",
        "\n",
        "### Load Weights\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "model.eval()\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Utilities\n",
        "\n",
        "### Gradient Clipping\n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "### AMP / Mixed Precision\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "with autocast():\n",
        "    output = model(inputs)\n",
        "\n",
        "### Count Parameters\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f'Total params: {total:,}')"
      ],
      "metadata": {
        "id": "MPjGvcH5eyID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotly"
      ],
      "metadata": {
        "id": "ZaFfofvOf0i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Scatter Plot\n",
        "fig = px.scatter(df, x='x_col', y='y_col', color='category', size='size_col', hover_name='label')\n",
        "fig.show()\n",
        "\n",
        "### Line Plot\n",
        "fig = px.line(df, x='date', y='value', color='series', markers=True)\n",
        "fig.show()\n",
        "\n",
        "### Area Plot\n",
        "fig = px.area(df, x='date', y='sales', color='segment', groupnorm='fraction')\n",
        "fig.show()\n",
        "\n",
        "### Bar Chart\n",
        "fig = px.bar(df, x='category', y='total', color='subgroup', text_auto=True)\n",
        "fig.update_layout(barmode='group')\n",
        "fig.show()\n",
        "\n",
        "### Treemap\n",
        "fig = px.treemap(df, path=['continent','country'], values='pop')\n",
        "fig.show()\n",
        "\n",
        "### Sunburst\n",
        "fig = px.sunburst(df, path=['continent','country','city'], values='pop')\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Distribution Plots\n",
        "\n",
        "### Histogram\n",
        "fig = px.histogram(df, x='age', nbins=30, color='gender', marginal='box')\n",
        "fig.show()\n",
        "\n",
        "### Box Plot\n",
        "fig = px.box(df, x='group', y='metric', points='all')\n",
        "fig.show()\n",
        "\n",
        "### Violin Plot\n",
        "fig = px.violin(df, y='score', x='method', color='method', box=True, points='all')\n",
        "fig.show()\n",
        "\n",
        "### Strip Plot\n",
        "fig = px.strip(df, x='condition', y='value', color='condition', jitter=0.3)\n",
        "fig.show()\n",
        "\n",
        "### 2D Density Heatmap\n",
        "fig = px.density_heatmap(df, x='x', y='y', nbinsx=40, nbinsy=40, color_continuous_scale='Viridis')\n",
        "fig.show()\n",
        "\n",
        "### 2D Density Contour\n",
        "fig = px.density_contour(df, x='feat1', y='feat2', color='cluster')\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Categorical Comparisons\n",
        "\n",
        "### Polar Bar\n",
        "fig = px.bar_polar(df, r='frequency', theta='direction', color='season')\n",
        "fig.show()\n",
        "\n",
        "### Funnel Chart\n",
        "fig = px.funnel(df, x='stage', y='users')\n",
        "fig.show()\n",
        "\n",
        "### Funnel Area\n",
        "fig = px.funnel_area(df, names='stage', values='users')\n",
        "fig.show()\n",
        "\n",
        "### Parallel Categories\n",
        "fig = px.parallel_categories(df, dimensions=['gender','class','pass'])\n",
        "fig.show()\n",
        "\n",
        "### Parallel Coordinates\n",
        "fig = px.parallel_coordinates(df, color='target', dimensions=df.columns[2:])\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Geographic Charts\n",
        "\n",
        "### Choropleth Map\n",
        "fig = px.choropleth(df, locations='iso_alpha', color='gdpPercap', hover_name='country', projection='natural earth')\n",
        "fig.show()\n",
        "\n",
        "### Geo Scatter\n",
        "fig = px.scatter_geo(df, lat='lat', lon='lon', color='group', size='pop')\n",
        "fig.show()\n",
        "\n",
        "### Geo Line\n",
        "fig = px.line_geo(df, lat='lat', lon='lon', color='route_id')\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Timeline & Stage Diagrams\n",
        "\n",
        "### Timeline (Gantt Chart)\n",
        "fig = px.timeline(df, x_start='start', x_end='finish', y='task', color='owner')\n",
        "fig.update_yaxes(autorange='reversed')\n",
        "fig.show()\n",
        "\n",
        "### Icicle\n",
        "fig = px.icicle(df, path=['phase','subphase','task'], values='hours')\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 6. 3D Plots\n",
        "\n",
        "### 3D Scatter\n",
        "fig = px.scatter_3d(df, x='x', y='y', z='z', color='label', symbol='label')\n",
        "fig.show()\n",
        "\n",
        "### 3D Line\n",
        "fig = px.line_3d(df, x='x', y='y', z='z', color='trial')\n",
        "fig.show()\n",
        "\n",
        "### Volume Plot\n",
        "fig = px.volume(vol_array)  # vol_array is a 3D NumPy array\n",
        "fig.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Useful Plotly Utilities\n",
        "\n",
        "### Update Layout\n",
        "fig.update_layout(title='My title', xaxis_title='X', yaxis_title='Y', template='plotly_white')\n",
        "\n",
        "### Update Marker\n",
        "fig.update_traces(marker=dict(size=10, opacity=0.7))\n",
        "\n",
        "### Save to HTML\n",
        "fig.write_html('figure.html', include_plotlyjs='cdn')\n",
        "\n",
        "### Set Default Renderer\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'notebook'\n",
        "\n",
        "---\n",
        "\n",
        "## 🔧 One-time Setup\n",
        "\n",
        "```python\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "pio.renderers.default = 'notebook'  # makes fig.show() unnecessary\n",
        "px.defaults.template = 'plotly_white'\n",
        "px.defaults.width = 800\n",
        "px.defaults.height = 500\n"
      ],
      "metadata": {
        "id": "aD5GXtWLf0SW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain"
      ],
      "metadata": {
        "id": "wK-La-LHg1eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🦜 LangChain Cheatsheet (Python)\n",
        "\n",
        "## 1. Setup & Initialization\n",
        "\n",
        "### Install LangChain\n",
        "pip install langchain openai\n",
        "\n",
        "### Load Environment Variables\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "### Import Core Modules\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Basic LLM Usage\n",
        "\n",
        "### Initialize LLM\n",
        "llm = OpenAI(temperature=0.7, openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "### Simple Prompt Completion\n",
        "prompt = \"What is the capital of France?\"\n",
        "response = llm(prompt)\n",
        "print(response)\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Using PromptTemplate\n",
        "\n",
        "### Create Prompt Template\n",
        "template = PromptTemplate(\n",
        "    input_variables=[\"animal_type\", \"pet_color\"],\n",
        "    template=\"What is a good name for a {animal_type} with {pet_color} color?\"\n",
        ")\n",
        "\n",
        "### Run LLMChain\n",
        "name_chain = LLMChain(llm=llm, prompt=template)\n",
        "response = name_chain.run({\"animal_type\": \"dog\", \"pet_color\": \"brown\"})\n",
        "print(response)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Using Chains\n",
        "\n",
        "### Simple Chain with Inputs\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "chain1 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Translate to Spanish: {input}\"))\n",
        "chain2 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Make it formal: {input}\"))\n",
        "\n",
        "overall_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
        "overall_chain.run(\"Hello, how are you?\")\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Tools & Agents\n",
        "\n",
        "### Load Tools\n",
        "from langchain.agents import load_tools\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "### Create Agent\n",
        "from langchain.agents import initialize_agent, AgentType\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "### Run Agent\n",
        "agent.run(\"Who is Marie Curie’s husband and what was his major discovery?\")\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Memory\n",
        "\n",
        "### Add Memory to Chain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "conversation = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(\"You are a helpful assistant. {history} Human: {input}\\nAI:\"),\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "conversation.run(\"What's the weather like today?\")\n",
        "conversation.run(\"What did I just ask you?\")\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Vectorstores & Embeddings (Optional)\n",
        "\n",
        "### Load Embeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "### FAISS Vector Store\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "db = FAISS.from_texts([\"hello world\", \"how are you\"], embedding=embedding)\n",
        "docs = db.similarity_search(\"hello\")\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Retrieval-Augmented Generation (RAG)\n",
        "\n",
        "### Create Retriever\n",
        "retriever = db.as_retriever()\n",
        "\n",
        "### RetrievalQA Chain\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "qa_chain.run(\"What is this about?\")\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Save & Load Chains\n",
        "\n",
        "### Save Chain\n",
        "chain.save(\"my_chain.json\")\n",
        "\n",
        "### Load Chain\n",
        "from langchain.chains import load_chain\n",
        "loaded = load_chain(\"my_chain.json\")\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Set Default OpenAI Key (optional)\n",
        "\n",
        "### Environment Setup\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\n"
      ],
      "metadata": {
        "id": "hjcJUzE0g0lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy"
      ],
      "metadata": {
        "id": "C1e_GL4Vg5Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧮 NumPy Cheatsheet\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### Import NumPy\n",
        "import numpy as np\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Creating Arrays\n",
        "\n",
        "### From List\n",
        "a = np.array([1, 2, 3])\n",
        "\n",
        "### Zeros / Ones\n",
        "z = np.zeros((2, 3))\n",
        "o = np.ones((2, 3))\n",
        "\n",
        "### Range / Linspace\n",
        "r = np.arange(0, 10, 2)\n",
        "l = np.linspace(0, 1, 5)\n",
        "\n",
        "### Identity Matrix\n",
        "I = np.eye(3)\n",
        "\n",
        "### Random Arrays\n",
        "rand = np.random.rand(2, 2)\n",
        "randn = np.random.randn(2, 2)\n",
        "randint = np.random.randint(0, 10, (2, 3))\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Array Inspection\n",
        "\n",
        "### Shape & Size\n",
        "a.shape\n",
        "a.size\n",
        "\n",
        "### Data Type\n",
        "a.dtype\n",
        "\n",
        "### Reshape\n",
        "a = a.reshape(3, 2)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Indexing & Slicing\n",
        "\n",
        "### Access Elements\n",
        "a[0, 1]\n",
        "\n",
        "### Slice Rows/Cols\n",
        "a[1:, :2]\n",
        "\n",
        "### Boolean Masking\n",
        "a[a > 5]\n",
        "\n",
        "### Fancy Indexing\n",
        "a[[0, 2], [1, 0]]\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Math Operations\n",
        "\n",
        "### Elementwise Math\n",
        "a + b\n",
        "a * b\n",
        "a ** 2\n",
        "np.exp(a)\n",
        "np.sqrt(a)\n",
        "\n",
        "### Matrix Multiplication\n",
        "np.dot(a, b)\n",
        "a @ b\n",
        "\n",
        "### Aggregation\n",
        "a.sum()\n",
        "a.mean()\n",
        "a.std()\n",
        "a.max()\n",
        "a.min()\n",
        "a.argmax()\n",
        "a.cumsum()\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Broadcasting\n",
        "\n",
        "### Scalar Operations\n",
        "a + 3\n",
        "a * 2\n",
        "\n",
        "### Row / Column Broadcasting\n",
        "a + np.array([[1], [2]])\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Linear Algebra\n",
        "\n",
        "### Transpose\n",
        "a.T\n",
        "\n",
        "### Inverse\n",
        "np.linalg.inv(a)\n",
        "\n",
        "### Determinant\n",
        "np.linalg.det(a)\n",
        "\n",
        "### Eigenvalues\n",
        "np.linalg.eig(a)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Random Seed & Sampling\n",
        "\n",
        "### Set Seed\n",
        "np.random.seed(42)\n",
        "\n",
        "### Shuffle Array\n",
        "np.random.shuffle(a)\n",
        "\n",
        "### Random Choice\n",
        "np.random.choice(a, size=3, replace=False)\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Save & Load\n",
        "\n",
        "### Save to .npy\n",
        "np.save('arr.npy', a)\n",
        "\n",
        "### Load .npy\n",
        "a = np.load('arr.npy')\n",
        "\n",
        "### Save to CSV\n",
        "np.savetxt('arr.csv', a, delimiter=',')\n",
        "\n",
        "### Load CSV\n",
        "a = np.loadtxt('arr.csv', delimiter=',')\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Useful Utilities\n",
        "\n",
        "### Stack Arrays\n",
        "np.vstack([a, b])\n",
        "np.hstack([a, b])\n",
        "\n",
        "### Split Arrays\n",
        "np.split(a, 2)\n",
        "np.array_split(a, 3)\n",
        "\n",
        "### Unique Elements\n",
        "np.unique(a)\n",
        "\n",
        "### Clip Values\n",
        "np.clip(a, 0, 1)\n",
        "\n",
        "### Replace NaNs\n",
        "np.nan_to_num(a)\n"
      ],
      "metadata": {
        "id": "F1csTxZ9g5iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scikit Learn"
      ],
      "metadata": {
        "id": "jivM2I2-hHF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🤖 Scikit-learn Cheatsheet\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### Import Core Modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Dataset Loading\n",
        "\n",
        "### Built-in Dataset\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "### Custom Dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv')\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Train/Test Split\n",
        "\n",
        "### Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Preprocessing\n",
        "\n",
        "### Standard Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Model Training\n",
        "\n",
        "### Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "### Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "### SVM\n",
        "from sklearn.svm import SVC\n",
        "model = SVC()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Predictions & Evaluation\n",
        "\n",
        "### Make Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "### Accuracy\n",
        "accuracy_score(y_test, y_pred)\n",
        "\n",
        "### Classification Report\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Cross-Validation\n",
        "\n",
        "### k-Fold Cross Validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(scores.mean())\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Pipelines\n",
        "\n",
        "### Create Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "pipe.score(X_test, y_test)\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Hyperparameter Tuning\n",
        "\n",
        "### Grid Search\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {'C': [0.1, 1, 10]}\n",
        "grid = GridSearchCV(LogisticRegression(), params, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(grid.best_params_)\n",
        "print(grid.best_score_)\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Common Models\n",
        "\n",
        "### Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "\n",
        "### Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "### KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "### Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "\n",
        "### Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n"
      ],
      "metadata": {
        "id": "xNEUkJFohHVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seaborn"
      ],
      "metadata": {
        "id": "IOk-gXqXhQL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🎨 Seaborn Cheatsheet\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### Import Libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "### Load Built-in Dataset\n",
        "df = sns.load_dataset(\"tips\")\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Distribution Plots\n",
        "\n",
        "### Histogram\n",
        "sns.histplot(df['total_bill'])\n",
        "plt.show()\n",
        "\n",
        "### KDE Plot\n",
        "sns.kdeplot(df['total_bill'], fill=True)\n",
        "plt.show()\n",
        "\n",
        "### Histogram + KDE\n",
        "sns.displot(df['total_bill'], kde=True)\n",
        "plt.show()\n",
        "\n",
        "### Box Plot\n",
        "sns.boxplot(x='day', y='total_bill', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Violin Plot\n",
        "sns.violinplot(x='day', y='total_bill', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Strip Plot (Scatter w/ Jitter)\n",
        "sns.stripplot(x='day', y='total_bill', data=df, jitter=True)\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Categorical Plots\n",
        "\n",
        "### Count Plot\n",
        "sns.countplot(x='day', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Bar Plot (Mean & CI)\n",
        "sns.barplot(x='day', y='tip', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Swarm Plot (Non-overlapping dots)\n",
        "sns.swarmplot(x='day', y='total_bill', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Point Plot\n",
        "sns.pointplot(x='time', y='tip', hue='sex', data=df)\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Relational Plots\n",
        "\n",
        "### Scatter Plot\n",
        "sns.scatterplot(x='total_bill', y='tip', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Line Plot\n",
        "sns.lineplot(x='size', y='tip', data=df)\n",
        "plt.show()\n",
        "\n",
        "### Relplot (Faceted)\n",
        "sns.relplot(x='total_bill', y='tip', hue='sex', col='time', data=df)\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Matrix Plots\n",
        "\n",
        "### Heatmap\n",
        "corr = df.corr(numeric_only=True)\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
        "plt.show()\n",
        "\n",
        "### Clustermap\n",
        "sns.clustermap(corr, annot=True, cmap='viridis')\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Pairwise Plots\n",
        "\n",
        "### Pairplot\n",
        "sns.pairplot(df, hue='sex')\n",
        "plt.show()\n",
        "\n",
        "### Jointplot\n",
        "sns.jointplot(x='total_bill', y='tip', data=df, kind='reg')\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Themes & Styles\n",
        "\n",
        "### Set Style\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "### Set Color Palette\n",
        "sns.set_palette('pastel')\n",
        "\n",
        "### Set Figure Size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Save Plot\n",
        "\n",
        "### Save to File\n",
        "plt.savefig(\"plot.png\", dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "JdVj9u72hQan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matplotlib"
      ],
      "metadata": {
        "id": "eh4g3ZQ9hVSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 📈 Matplotlib Cheatsheet\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### Import Modules\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "### Create Sample Data\n",
        "x = np.linspace(0, 10, 100)\n",
        "y = np.sin(x)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Basic Plotting\n",
        "\n",
        "### Line Plot\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "### Scatter Plot\n",
        "plt.scatter(x, y)\n",
        "plt.show()\n",
        "\n",
        "### Bar Plot\n",
        "categories = ['A', 'B', 'C']\n",
        "values = [5, 3, 7]\n",
        "plt.bar(categories, values)\n",
        "plt.show()\n",
        "\n",
        "### Horizontal Bar\n",
        "plt.barh(categories, values)\n",
        "plt.show()\n",
        "\n",
        "### Histogram\n",
        "data = np.random.randn(1000)\n",
        "plt.hist(data, bins=30)\n",
        "plt.show()\n",
        "\n",
        "### Box Plot\n",
        "plt.boxplot(data)\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Customization\n",
        "\n",
        "### Labels & Title\n",
        "plt.plot(x, y)\n",
        "plt.title(\"Sine Curve\")\n",
        "plt.xlabel(\"x-axis\")\n",
        "plt.ylabel(\"y-axis\")\n",
        "plt.show()\n",
        "\n",
        "### Grid\n",
        "plt.plot(x, y)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "### Legends\n",
        "plt.plot(x, y, label='Sine')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Subplots\n",
        "\n",
        "### 1 Row, 2 Columns\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(x, y)\n",
        "plt.title(\"Left\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(x, -y)\n",
        "plt.title(\"Right\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Figures\n",
        "\n",
        "### Create New Figure\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "### Save Figure\n",
        "plt.plot(x, y)\n",
        "plt.savefig(\"plot.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Styles & Appearance\n",
        "\n",
        "### Set Style\n",
        "plt.style.use('ggplot')\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "### Colors & Markers\n",
        "plt.plot(x, y, color='purple', linestyle='--', marker='o')\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Axes Object API\n",
        "\n",
        "### Create Axes\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y)\n",
        "ax.set_title(\"With Axes Object\")\n",
        "ax.set_xlabel(\"x\")\n",
        "ax.set_ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Advanced Plots\n",
        "\n",
        "### Fill Between\n",
        "plt.fill_between(x, y, alpha=0.3)\n",
        "plt.plot(x, y)\n",
        "plt.show()\n",
        "\n",
        "### Log Scale\n",
        "plt.semilogy(x, np.exp(x))\n",
        "plt.show()\n",
        "\n",
        "### Twin Axes\n",
        "fig, ax1 = plt.subplots()\n",
        "ax2 = ax1.twinx()\n",
        "ax1.plot(x, y, 'g-')\n",
        "ax2.plot(x, np.cos(x), 'b--')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xHOhIX7nhVfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow"
      ],
      "metadata": {
        "id": "15VHzKdJhjvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚡️ TensorFlow Cheatsheet\n",
        "\n",
        "## 1. Setup\n",
        "\n",
        "### Import TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "### Check Version\n",
        "tf.__version__\n",
        "\n",
        "### Set Seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Creating Tensors\n",
        "\n",
        "### Constant\n",
        "x = tf.constant([[1., 2.], [3., 4.]])\n",
        "\n",
        "### Variable\n",
        "v = tf.Variable(tf.random.normal([3, 3]))\n",
        "\n",
        "### Zeros / Ones\n",
        "z = tf.zeros([2, 3])\n",
        "o = tf.ones([2, 3])\n",
        "\n",
        "### Range\n",
        "r = tf.range(10)\n",
        "\n",
        "### Random Normal\n",
        "rn = tf.random.normal([2, 2])\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Tensor Operations\n",
        "\n",
        "### Element-wise Math\n",
        "y = x + 3\n",
        "\n",
        "### Matrix Multiplication\n",
        "prod = tf.matmul(x, v)\n",
        "\n",
        "### Reshape\n",
        "x = tf.reshape(x, [-1])\n",
        "\n",
        "### Concatenate\n",
        "cat = tf.concat([x, y], axis=0)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. GPU / Device Placement\n",
        "\n",
        "### List GPUs\n",
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "### Run on GPU\n",
        "with tf.device('/GPU:0'):\n",
        "    y = x * 2\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Automatic Differentiation\n",
        "\n",
        "### GradientTape\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x)\n",
        "    y = tf.reduce_sum(x ** 2)\n",
        "grad = tape.gradient(y, x)\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Building a Keras Model\n",
        "\n",
        "### Sequential Model\n",
        "from tensorflow.keras import layers, models\n",
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "### Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Training\n",
        "\n",
        "### Fit\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Evaluation & Prediction\n",
        "\n",
        "### Evaluate\n",
        "model.evaluate(X_test, y_test)\n",
        "\n",
        "### Predict\n",
        "preds = model.predict(X_new)\n",
        "\n",
        "---\n",
        "\n",
        "## 9. tf.data Pipeline\n",
        "\n",
        "### Create Dataset\n",
        "ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "ds = ds.shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Saving & Loading\n",
        "\n",
        "### Save Full Model\n",
        "model.save('model.h5')\n",
        "\n",
        "### Load Model\n",
        "model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "### Save Weights\n",
        "model.save_weights('weights.ckpt')\n",
        "\n",
        "### Load Weights\n",
        "model.load_weights('weights.ckpt')\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Callbacks\n",
        "\n",
        "### Early Stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(patience=3, restore_best_weights=True)\n",
        "model.fit(X_train, y_train, epochs=50, callbacks=[es])\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Mixed Precision\n",
        "\n",
        "### Enable Mixed Precision\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n"
      ],
      "metadata": {
        "id": "nF6M8Rf-hkuy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}